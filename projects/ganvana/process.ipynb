{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4fc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c3b6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_cate1_cate2 = json.load(open(\"D:/_WangKe/scikkk.github.io/projects/ganvana/tags_cate1_cate2.json\", \"r\", encoding=\"utf-8\"))\n",
    "tags_cate1_cate2[\"tags\"] = {item['id']: item for item in tags_cate1_cate2[\"tags\"]}\n",
    "id_cates = {item['id']: item for item in tags_cate1_cate2[\"cate1List\"]+tags_cate1_cate2[\"cate2List\"]}\n",
    "name_cates = {item['name']: item for item in tags_cate1_cate2[\"cate1List\"]+tags_cate1_cate2[\"cate2List\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6e247e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 5, 7, 21, 25, 50, 160000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def convert_timestamp_to_datetime(timestamp):\n",
    "    timestamp_in_seconds = timestamp / 1000.0\n",
    "    dt = datetime.datetime.fromtimestamp(timestamp_in_seconds)\n",
    "    return dt\n",
    "convert_timestamp_to_datetime(1746624350160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2dca4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f):\n",
    "            data.append(json.loads(line))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdaad4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mall_jsonl2csv(jsonl_file, csv_file, delimiter=','):\n",
    "    vacant_list = []\n",
    "    data = load_jsonl(jsonl_file)\n",
    "    headers = [     \n",
    "            'page', 'id', \n",
    "            'tag', \n",
    "            # 'tag_name',\n",
    "            'group', \n",
    "            'cate1', 'cate1_name',\n",
    "            'cate2', 'cate2_name',\n",
    "            'status', \n",
    "            'name', 'lat_name', 'sn', \n",
    "            'author', \n",
    "            'price', 'usd_price', 'profit_rate',\n",
    "            'amount', 'size', 'condition', 'area', \n",
    "            'thumb', 'thumb_big', \n",
    "            'desc', 'descEn', 'content', 'created_at', 'updated_at', 'indexShow', \n",
    "            'cate_name', 'cate_lat_name',  \n",
    "            'cls_ph', 'cls_cl1', 'cls_cl2', 'cls_cl3', \n",
    "            'cls_or1', 'cls_or2', 'cls_or3', 'cls_or4', 'cls_or5', \n",
    "            'cls_fa1', 'cls_ch', \n",
    "               ]\n",
    "    for entry in tqdm(data, desc=\"Processing JSONL\"):\n",
    "        if len(entry) <= 1:\n",
    "            vacant_list.append(entry[\"id\"])\n",
    "            continue\n",
    "        # page\n",
    "        entry[\"page\"] = f\"https://www.ganvana.com/mall/goods/{entry['id']}\"\n",
    "        # classification\n",
    "        classification = [\"ph\", \"cl1\", \"cl2\", \"cl3\", \"or1\", \"or2\", \"or3\", \"or4\", \"or5\", \"fa1\", \"ch\"]\n",
    "        if \"classification\" not in entry or not entry[\"classification\"]:\n",
    "            entry[\"classification\"] = {}\n",
    "        for c in classification:\n",
    "            entry[f\"cls_{c}\"] = entry[\"classification\"].get(c, '')\n",
    "        del entry[\"classification\"]\n",
    "        # cate1, cate2\n",
    "        cate1 = min(entry.get(\"cate1\", 0), entry.get(\"cate2\", 0))\n",
    "        cate2 = max(entry.get(\"cate1\", 0), entry.get(\"cate2\", 0))\n",
    "        entry[\"cate1\"], entry[\"cate2\"] = cate1, cate2\n",
    "        if cate1 in id_cates:\n",
    "            entry[\"cate1_name\"] = id_cates[cate1][\"name\"]\n",
    "        else:\n",
    "            entry[\"cate1_name\"] = ''\n",
    "        if cate2 in id_cates:\n",
    "            entry[\"cate2_name\"] = id_cates[cate2][\"name\"]\n",
    "            entry[\"cate1_name\"] = id_cates[id_cates[cate2][\"father\"]][\"name\"]\n",
    "        else:\n",
    "            entry[\"cate2_name\"] = ''\n",
    "\n",
    "        if \"name\" in entry and entry[\"name\"] and not entry[\"cate2_name\"]:\n",
    "            for candidates in [\"亚纳特螺科\",\"德亚奇螺科\", \"豆蜗牛科\", \"小豆螺科\", \"亚轮螺科\", \"塔格螺科\", \"薄泥蜗牛科\", \"拟阿勇螺科\", \"吉奥蜗牛科\", \"管螺科\"]:\n",
    "                if candidates in entry[\"name\"] or candidates[:-1] in entry[\"name\"]:\n",
    "                    entry[\"cate2_name\"] = name_cates[candidates][\"name\"]\n",
    "                    entry[\"cate1_name\"] = id_cates[name_cates[candidates][\"father\"]][\"name\"]\n",
    "                    # print(entry[\"cate1_name\"], entry[\"cate2_name\"], entry[\"name\"])\n",
    "                    break\n",
    "        \n",
    "        if entry.get(\"price\", 0) and entry.get(\"usd_price\", 0):\n",
    "            entry[\"profit_rate\"] = round((entry[\"price\"] - entry[\"usd_price\"]) / entry[\"usd_price\"], 2)\n",
    "\n",
    "        #     for name_len in range(len(entry[\"name\"])):\n",
    "        #         possible_name = entry[\"name\"][name_len:]\n",
    "        #         if possible_name in name_cates:\n",
    "        #             entry[\"cate2_name\"] = name_cates[possible_name][\"name\"]\n",
    "        #             entry[\"cate1_name\"] = id_cates[name_cates[possible_name][\"father\"]][\"name\"]\n",
    "        #             print(entry[\"cate1_name\"], entry[\"cate2_name\"], entry[\"name\"])\n",
    "        #             break\n",
    "        #         elif possible_name+'科' in name_cates:\n",
    "        #             possible_name = possible_name+'科'\n",
    "        #             entry[\"cate2_name\"] = name_cates[possible_name][\"name\"]\n",
    "        #             entry[\"cate1_name\"] = id_cates[name_cates[possible_name][\"father\"]][\"name\"]\n",
    "        #             print(entry[\"cate1_name\"], entry[\"cate2_name\"], entry[\"name\"])\n",
    "        #             break\n",
    "      \n",
    "        if 'created_at' in entry and isinstance(entry['created_at'], int):\n",
    "            entry['created_at'] = convert_timestamp_to_datetime(entry['created_at'])\n",
    "        if 'updated_at' in entry and isinstance(entry['updated_at'], int):\n",
    "            entry['updated_at'] = convert_timestamp_to_datetime(entry['updated_at'])\n",
    "    with open(csv_file, 'w', encoding='utf-8') as f:\n",
    "        firstline = delimiter.join(headers) + '\\n'\n",
    "        f.write(firstline)\n",
    "        print(firstline)\n",
    "        for entry in tqdm(data, desc=\"Converting to CSV\"):\n",
    "            row = delimiter.join([\n",
    "                    f'\"{item}\"'.strip() for item in \n",
    "                    [str(entry.get(header, '')).strip() for header in headers]\n",
    "                ])\n",
    "            f.write(row + '\\n')\n",
    "    with open(jsonl_file.replace('.jsonl', '_vacant.jsonl'), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(vacant_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1ce761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "getGoodsInfo = \"D:/_WangKe/scikkk.github.io/projects/ganvana/mall/getGoodsInfo.jsonl\"\n",
    "# mall_jsonl2csv(getGoodsInfo, getGoodsInfo.replace('.jsonl', '.csv'), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d4a3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def auction_jsonl2csv(jsonl_file, csv_file, delimiter=','):\n",
    "    vacant_list = []\n",
    "    data = load_jsonl(jsonl_file)\n",
    "    headers = ['page', 'id', 'auction_id', 'status', \n",
    "               'family', 'lat_family', \n",
    "               'goods_name', 'lat_name', \n",
    "               'author', \n",
    "               'goods_sn', 'thumb', 'thumb_big', \n",
    "               'size', 'product_area', 'desc', \n",
    "            #    'more_img', \n",
    "               'bid_time', \n",
    "               'created_at',\n",
    "               'winner_who', 'winner_price', 'winner_nickname', 'winner_headimg', 'winner_rec_id'\n",
    "               ]\n",
    "\n",
    "    print(headers)\n",
    "    for entry in tqdm(data, desc=\"Processing JSONL\"):\n",
    "        if len(entry) <= 1:\n",
    "            vacant_list.append(entry[\"id\"])\n",
    "            continue\n",
    "        \n",
    "        entry[\"page\"] = f\"https://www.ganvana.com/auction/item/{entry['id']}\"\n",
    "        \n",
    "        if 'created_at' in entry and isinstance(entry['created_at'], int):\n",
    "            entry['created_at'] = convert_timestamp_to_datetime(entry['created_at'])\n",
    "            \n",
    "    with open(csv_file, 'w', encoding='utf-8') as f:\n",
    "        firstline = delimiter.join(headers) + '\\n'\n",
    "        f.write(firstline)\n",
    "        print(firstline)\n",
    "        for entry in tqdm(data, desc=\"Converting to CSV\"):\n",
    "            row = delimiter.join([\n",
    "                    f'\"{item}\"'.strip() for item in \n",
    "                    [str(entry.get(header, '')).strip() for header in headers]\n",
    "                ])\n",
    "            f.write(row + '\\n')\n",
    "    with open(jsonl_file.replace('.jsonl', '_vacant.jsonl'), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(vacant_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bbfa16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41852it [00:00, 55666.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['page', 'id', 'auction_id', 'status', 'family', 'lat_family', 'goods_name', 'lat_name', 'author', 'goods_sn', 'thumb', 'thumb_big', 'size', 'product_area', 'desc', 'bid_time', 'created_at', 'winner_who', 'winner_price', 'winner_nickname', 'winner_headimg', 'winner_rec_id']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL: 100%|██████████| 41852/41852 [00:00<00:00, 337517.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page,id,auction_id,status,family,lat_family,goods_name,lat_name,author,goods_sn,thumb,thumb_big,size,product_area,desc,bid_time,created_at,winner_who,winner_price,winner_nickname,winner_headimg,winner_rec_id\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to CSV: 100%|██████████| 41852/41852 [00:00<00:00, 55786.71it/s]\n"
     ]
    }
   ],
   "source": [
    "getGoodsInfo = \"D:/_WangKe/scikkk.github.io/projects/ganvana/auction/getItem.jsonl\"\n",
    "auction_jsonl2csv(getGoodsInfo, getGoodsInfo.replace('.jsonl', '.csv'), delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
